# 2023-Big-Data-Driven-Artificial-Intelligence
+ **课程名称：** 大数据驱动的人工智能
+ **英文名称：** Big Data Driven Artificial Intelligence
+ **课程简介：**<br>
围棋、蛋白质结构预测、新质子模型的发现、辅助数学定理证明，所有这些不同领域的难题都正在被新兴人工智能技术逐一攻破。人工智能， 特别      是以大数据、机器学习、神经网络等技术为主体的智能技术，近年来获得了迅猛的发展，它正在与各个学科发生交叉、融合，逐渐演化为一种解决各种复杂系统问题的跨学科方论，成为支撑复杂系统分析与建模的重要新兴技术。<br>
本课程面向全校具有一定理工科背景和编程技术基础的硕士研究生开放，全面介绍基于大数据技术驱动为主的人工智能技术的最新进展，包括但不限于：神经网络、深度学习、强化学习、因果推断、生成模型、语言模型、面向科学发现的AI等前沿领域。希望学员能够在本课程的学习过程中了解数据驱动的人工智能最新方法、技术，和前沿发展情况，同时通过一定的课程项目实践，能够具备利用人工智能解决复杂问题的实操、编程能力。<br>
+ **教学目标：**<br>
  本课程的教学目标主要包括：<br>
（1）对人工智能的发展历史和前沿应用、科研领域的基本了解；<br>
（2）对深度学习、神经网络、强化学习、因果推断、数据驱动建模等基本知识和方法的掌握；<br>
（3）掌握PyTorch编程基本方法，用于完成系列课程实践项目<br>
+ **预期效果：**<br>
  通过本课程的学习，学生能够了解当前大数据驱动的人工智能的最新进展；掌握机器学习、神经网络、数据驱动建模等人工智能核心技术的基本概念和基本方法；掌握应用PyTorch平台使用的基本技能，可以用于简单项目开发。<br>
+ **教学方式：** 课堂讲授+课程实践
+ **考察方式：** 考察
+ **主要内容及教学安排：**<br>
**第一章：大数据与人工智能简介**                       2学时<br>
主要内容： （1）介绍人工智能简史及其流派；（2） 大数据人工智能技术的兴起与前沿进展；（3）应用举例：ChatGPT、蛋白质折叠预测等<br>
重点、难点：人工智能与机器学习的关系；大数据驱动的人工智能与机器学习之间的关系<br>
课前学习要求： 调研你专业领域的最新人工智能应用项目<br>
作业：无<br>

  **第二章：自动微分与PyTorch编程**     2学时（课堂讲授学时 +课程实践学时 ）<br>
  主要内容： 介绍什么是自动微分技术，它的应用场景包括哪些；介绍PyTorch自动微分编程平台；应用Pytorch举例<br>
  重点、难点：理解自动微分概念及其与传统数值计算的差别；掌握PyTorch应用的基本方法<br>
  课前学习要求： 自行安装PyTorch的最新版本，并熟悉编程环境<br>
  作业：用PyTorch实现简单的线性回归算法<br>

  **第三章：机器学习的基本概念**   2学时（课堂讲授学时 +课程实践学时 ）<br>
  主要内容： 什么是机器学习？机器学习的简单分类有哪些？机器学习的基本步骤有哪些？机器学习的性能评估；机器学习中的常见问题；简单前馈神经网络与反向传播算法介绍。<br>
  重点、难点：混淆矩阵、过拟合等基本概念的理解<br>
  课前学习要求： 了解机器学习基本概念<br>
  作业：用前馈神经网络实现共享单车预测问题<br>

  **第四章：常见神经网络架构**   4学时（课堂讲授学时 +课程实践学时 ）<br>
  主要内容： 前馈神经网络、卷积神经网络、循环神经网络等基本常见神经网络架构与编程实践；图像处理与自然语言处理中的分类问题与实践；数据处理的基本方法<br>
  重点、难点：理解不同架构神经网络的区别和应用场景；掌握图像处理与自然语言处理的基本技巧<br>
  课前学习要求： 前馈神经网络、卷积神经网络、循环神经网络等基本常见神经网络架构的预习<br>
  作业：用卷积神经网络实现手写体识别/用前馈或循环神经网络实现文本分类<br>

  **第五章：表示学习理论**   2学时（课堂讲授学时 +课程实践学时 ）<br>
  主要内容： 表示学习理论；表示学习与迁移学习；预训练与迁移学习；图像的迁移学习举例；词向量技术与应用简介<br>
  重点、难点：理解特征与表示的基本概念；理解深度学习与表示学习的基本联系和区别；理解迁移学习技术的基本原理；理解词向量技术的基本原理。<br>
  课前学习要求： 了解迁移学习和词向量技术<br>
  作业：基于词向量的语言翻译<br>

  **第六章：从深度神经网络到Neural ODE**   2学时（课堂讲授学时 +课程实践学时 ）<br>
  主要内容： 常微分方程求解的数值算法；残差网络； Neural ODE原理；应用实例；最优控制与伴随算法<br>
  重点、难点：理解常微分方程数值求解算法与残差网络之间的相似性；Neural ODE伴随解法、最优控制与反向传播算法的关系。<br>
  课前学习要求： 常微分方程数值解法、拉格朗日优化方法、泛函优化问题<br>
  作业：在图像分类任务上对比Neural ODE与深度残差网络<br>

  **第七章：生成模型概览**   4 学时（课堂讲授学时 +课程实践学时 ）<br>
  主要内容： 生成模型与预测模型的区别；生成模型的分类；GAN、VAE、Normalizing Flow、Diffusion Model等生成模型简介<br>
  重点、难点：理解GAN、VAE、Normalizing Flow、Diffusion Model的基本原理和局限性<br>
  课前学习要求： 了解无监督学习与生成模型<br>
  作业：选一种生成模型，在图像数据集上实现<br>

  **第八章：复杂系统数据驱动建模**   2学时（课堂讲授学时 +课程实践学时 ）<br>
  主要内容： 复杂系统；复杂系统建模方法；复杂系统数据驱动建模方法；包含了决策与反馈的完整闭环；因果规律的学习；基于世界模型的强化学习框架。<br>
  重点、难点：理解观测数据与干预数据的不同；理解强化学习<br>
  课前学习要求： 复杂系统基本知识<br>
  作业：无<br>

  **第九章：图神经网络**   4 学时（课堂讲授学时 +课程实践学时 ）<br>
  主要内容： 图与网络；图神经网络基本原理；图神经网络的基本应用：节点分类；基于图神经网络的复杂系统数据驱动建模<br>
  重点、难点：理解图神经网络的基本原理<br>
  课前学习要求： 复杂网络与动力学<br>
  作业：无<br>

  **第十章：从Transformer到ChatGPT**   2 学时（课堂讲授学时 +课程实践学时 ）<br>
  主要内容： 注意力机制；自注意力机制与网络结构学习；Transformer架构介绍；Transformer的应用；基于语言模型的自监督学习机制； BERT、GPT3、ChatGPT等架构介绍<br>
  重点、难点：理解注意力机制；理解Transformer的基本原理；理解语言模型与自监督学习<br>
  课前学习要求： 了解ChatGPT<br>
  作业：无<br>

  **第十章：因果机器学习**   2 学时（课堂讲授学时 +课程实践学时 ）<br>
  主要内容： 因果与相关；因果推断简介；因果发现简介；因果表示学习。<br>
  重点、难点：理解因果与相关，理解Pearl的三层阶梯理论<br>
  课前学习要求： 了解概率图模型<br>
  作业：无<br>

  **第十一章：强化学习**   4 学时（课堂讲授学时 +课程实践学时 ）<br>
  主要内容： 强化学习基本框架；强化学习分类；Q学习算法；深度强化学习；基于World Model的强化学习算法；因果与强化学习；强化学习与控制/决策<br>
  重点、难点：理解强化学习基本原理、Q算法、深度强化学习算法与World Model的基本原理<br>
  课前学习要求： 了解强化学习<br>
  作业：无<br>
